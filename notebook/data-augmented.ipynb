{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data augmentation using gensim and word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "import stanfordnlp\n",
    "\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\Andreas Chandra\\\\stanfordnlp_resources\\\\id_gsd_models\\\\id_gsd_tokenizer.pt', 'lang': 'id', 'shorthand': 'id_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\Andreas Chandra\\\\stanfordnlp_resources\\\\id_gsd_models\\\\id_gsd_tagger.pt', 'pretrain_path': 'C:\\\\Users\\\\Andreas Chandra\\\\stanfordnlp_resources\\\\id_gsd_models\\\\id_gsd.pretrain.pt', 'lang': 'id', 'shorthand': 'id_gsd', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\Andreas Chandra\\\\stanfordnlp_resources\\\\id_gsd_models\\\\id_gsd_lemmatizer.pt', 'lang': 'id', 'shorthand': 'id_gsd', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': 'C:\\\\Users\\\\Andreas Chandra\\\\stanfordnlp_resources\\\\id_gsd_models\\\\id_gsd_parser.pt', 'pretrain_path': 'C:\\\\Users\\\\Andreas Chandra\\\\stanfordnlp_resources\\\\id_gsd_models\\\\id_gsd.pretrain.pt', 'lang': 'id', 'shorthand': 'id_gsd', 'mode': 'predict'}\n",
      "Done loading processors!\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "nlp = stanfordnlp.Pipeline(lang=\"id\",use_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_cleaned = pickle.load(open(os.path.join(data_path, 'cleaned', 'all_data_cleaned.pkl'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(os.path.join(data_path, \"support\", \"idwiki_word2vec_200.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_a = d_cleaned['train_a']\n",
    "d_train_b = d_cleaned['train_b']\n",
    "\n",
    "d_dev_a = d_cleaned['dev_a']\n",
    "d_dev_b = d_cleaned['dev_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_master = d_train_a.append(d_train_b)\n",
    "d_dev_master = d_dev_a.append(d_dev_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_master.reset_index(drop=True, inplace=True)\n",
    "d_dev_master.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_unique(df, label):\n",
    "    text = \" \".join(df[df['LABEL'] == label]['response_2'])\n",
    "    \n",
    "    text_stemmed = stemmer.stem(text)\n",
    "\n",
    "    word_list = set(word_tokenize(text_stemmed))\n",
    "    \n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentences(query, label):\n",
    "    response_2 = d_train[(d_train.word_list_2.apply(lambda x: query in x)) & (d_train['LABEL'] == label)][\"response_2\"]\n",
    "    \n",
    "    return response_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_augmented(d_train):\n",
    "    \n",
    "    d_train_aug = d_train.copy()\n",
    "\n",
    "    d_train['word_list_2'] = d_train.response_2.apply(word_tokenize)\n",
    "    \n",
    "    d_true = d_train[d_train[\"LABEL\"] == 1]\n",
    "\n",
    "    d_false = d_train[d_train[\"LABEL\"] == 0]\n",
    "\n",
    "    true_words = \" \".join(d_true.response_2)\n",
    "    false_words = \" \".join(d_false.response_2)\n",
    "\n",
    "    true_word_freq = Counter(word_tokenize(true_words))\n",
    "\n",
    "    false_word_freq = Counter(word_tokenize(false_words))\n",
    "    \n",
    "    d_word_freq_true = pd.DataFrame(data = {'word': list(true_word_freq.keys()),\n",
    "                                  'freq': list(true_word_freq.values())})\n",
    "\n",
    "    d_word_freq_false = pd.DataFrame(data = {'word': list(false_word_freq.keys()),\n",
    "                                  'freq': list(false_word_freq.values())})\n",
    "    \n",
    "    d_word_freq = pd.merge(d_word_freq_true, d_word_freq_false, how = 'outer', on = 'word', suffixes=('_true', '_false'))\n",
    "    \n",
    "    d_word_freq_nona = d_word_freq[d_word_freq.isna().sum(axis = 1) == 0]\n",
    "\n",
    "    d_word_freq_nona['total'] = d_word_freq_nona.freq_true + d_word_freq_nona.freq_false\n",
    "\n",
    "    d_word_freq_nona['selisih'] = d_word_freq_nona.freq_true - d_word_freq_nona.freq_false\n",
    "\n",
    "    d_word_freq_nona.sort_values(by=['selisih', 'total'], ascending = False)\n",
    "\n",
    "    d_word_more_true = d_word_freq_nona[d_word_freq_nona.selisih > 10].sort_values('selisih')\n",
    "    d_word_more_false = d_word_freq_nona[d_word_freq_nona.selisih < 0].sort_values('selisih')\n",
    "    \n",
    "    for index in d_word_more_false.index:\n",
    "        doc = nlp(d_word_more_false.loc[index, 'word'])\n",
    "        for sent in doc.sentences:\n",
    "            for word in sent.words:\n",
    "                d_word_more_false.loc[index, 'upos'] = word.upos\n",
    "\n",
    "    for index in d_word_more_true.index:\n",
    "        doc = nlp(d_word_more_true.loc[index, 'word'])\n",
    "        for sent in doc.sentences:\n",
    "            for word in sent.words:\n",
    "                d_word_more_true.loc[index, 'upos'] = word.upos\n",
    "\n",
    "    d_word_true_selected = d_word_more_true[d_word_more_true.upos.isin([\"NOUN\", \"VERB\", \"ADJ\"])]\n",
    "\n",
    "    d_word_false_selected = d_word_more_false[d_word_more_false.upos.isin([\"NOUN\", \"VERB\", \"ADJ\"])]\n",
    "\n",
    "    d_word_true_selected.shape\n",
    "\n",
    "    d_word_false_selected.shape\n",
    "    \n",
    "    label = 0\n",
    "    for index in tqdm(d_word_false_selected.index):\n",
    "        word_ = d_word_false_selected.loc[index, \"word\"];\n",
    "        sentences = get_sentences(word_, label)\n",
    "        if len(sentences):\n",
    "            for response in sentences:\n",
    "                try:\n",
    "                    word_similar_list = model.wv.most_similar(word_)\n",
    "                except:\n",
    "                    word_similar_list = []\n",
    "\n",
    "                if len(word_similar_list):\n",
    "                    for word, prob in word_similar_list[:5]:\n",
    "                        d_train_aug = d_train_aug.append({'response_2': response, 'LABEL': label}, ignore_index=True)\n",
    "        else:\n",
    "            print(\"query\", word_)\n",
    "    \n",
    "    label = 1\n",
    "    for index in tqdm(d_word_true_selected.index):\n",
    "        word_ = d_word_true_selected.loc[index, \"word\"];\n",
    "        sentences = get_sentences(word_, label)\n",
    "        if len(sentences):\n",
    "            for response in sentences:\n",
    "                try:\n",
    "                    word_similar_list = model.wv.most_similar(word_)\n",
    "                except:\n",
    "                    word_similar_list = []\n",
    "\n",
    "                if len(word_similar_list):\n",
    "                    for word, prob in word_similar_list[:5]:\n",
    "        #                 print(\"word\", word, \"word_\", word_)\n",
    "        #                 print(response.replace(word_, word))\n",
    "                        d_train_aug = d_train_aug.append({'response_2': response, 'LABEL': label}, ignore_index=True)\n",
    "        else:\n",
    "            print(\"query\", word_)\n",
    "    \n",
    "    return d_train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:07<00:00,  6.79it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:24<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 54/54 [00:08<00:00, 10.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:23<00:00,  1.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 49/49 [00:07<00:00,  9.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 26/26 [00:26<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 44/44 [00:08<00:00,  8.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:22<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kfold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Andreas Chandra\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [00:05<00:00,  6.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 23/23 [00:22<00:00,  1.85s/it]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for train, test in kf.split(d_train_master.response_2, d_train_master.LABEL):\n",
    "    print(\"kfold\", index)\n",
    "    d_train = d_train_master.loc[train, ['RES_ID', 'RESPONSE', 'LABEL', 'word_list', 'response_2']]\n",
    "    d_test = d_train_master.loc[test, ['RES_ID', 'RESPONSE', 'LABEL', 'word_list', 'response_2']]\n",
    "    \n",
    "    d_train.reset_index(drop=True, inplace=True)\n",
    "    d_test.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    d_train_aug = generate_augmented(d_train)\n",
    "    \n",
    "    pickle.dump({'train': d_train_aug, 'test': d_test, 'dev': d_dev_master}, open('../data/cleaned/kfold/all_data_cleaned_augmented_false_kfold_{}.pkl'.format(index), 'wb'))\n",
    "    \n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
